{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![02_01](https://github.com/rasbt/python-machine-learning-book/blob/master/code/ch02/images/02_01.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "感知器 (perceptron) 算法的历史就不介绍了，大意就是想法来自生物学的神经元的一些工作方式，多个生物信号 (input singals) 到达树突 (dentrites)并进入细胞核 (cell nucleus)，如果这些信号的效果累加达到一个阈值，那么通过轴突 (axon) 产生一个输出信号 (output signals)。在有监督学习与分类的背景下，这样的算法可被用来预测一个样本是否属于某个类别。\n",
    "\n",
    "正式地，我们可以把这个问题表述为一个二分类任务，并且为了简单起见，将这两个类别分别定义为 1 (正类) 与 -1（负类）。接着定义一个激活函数 (activation function) $\\phi (z)$, 它输入的是 $\\mathbf{x}$ 与其对应的权重向量 $\\mathbf{w}$ 的一个线性组合, 这里的 $z$ 也就是所谓的 net input ($z=w_1x_1 + \\ldots + w_mx_m$):\n",
    "\n",
    "$$\n",
    "\\mathbf{w} = \n",
    "\\left[  \n",
    "\\begin{array}{c}  \n",
    "          w_{1} \\\\  \n",
    "          \\vdots \\\\  \n",
    "          w_{m}  \n",
    "\\end{array}  \n",
    "\\right],\n",
    "\\mathbf{x} = \n",
    "\\left[  \n",
    "\\begin{array}{c}  \n",
    "          x_{1} \\\\  \n",
    "          \\vdots \\\\  \n",
    "          x_{m}  \n",
    "\\end{array}  \n",
    "\\right]\n",
    "$$\n",
    "\n",
    "对于一个指定样本 $\\mathbf{x}^{(i)}$, 如果 $\\phi(z)$ 的输出值大于预先定义的一个阈值 $\\Theta$, 那么就预测其类别 1. 否则，预测为类别 -1. 在感知器算法中，激活函数 $\\phi(\\cdot)$ 是一个简单的单位阶跃函数 (unit step function), 有时也叫赫维赛德阶跃函数 (Heaviside step function):\n",
    "\n",
    "$$\n",
    "\\phi(z) =\n",
    "\\begin{cases}\n",
    "1  &if~z \\geq \\theta \\\\\n",
    "-1 &~otherwise\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "![02_02](https://github.com/rasbt/python-machine-learning-book/blob/master/code/ch02/images/02_02.png?raw=true)\n",
    "\n",
    "为了简便起见，我们可以将 $\\theta$ 移到等式左侧并定义 $w_0 = -\\theta$, $x_0 = 1$, 那么就可以将 $z$ 写成一个更为紧凑的形式:\n",
    "\n",
    "$$\n",
    "z=w_0x_0 + w_1x_1 + \\ldots + w_mx_m = \\mathbf{w}^{T}\\mathbf{x}\n",
    "$$\n",
    "\n",
    "感知器算法步骤如下：\n",
    "\n",
    "1. 将权重初始化为 0 或一个很小的随机数\n",
    "2. 对于每个训练样本 $\\mathbf{x}^{(i)}$ 执行下列步骤：\n",
    "    1. 计算输出值 $\\hat{y}$.\n",
    "    2. 更新权重\n",
    "\n",
    "这里的输出值就是我们所要预测的类标签（1, -1）, 同时更新权重向量 $\\mathbf{w}$ 中的每个权重 $w_j$:\n",
    "\n",
    "$$\n",
    "w_j := w_j + \\Delta w_j\n",
    "$$\n",
    "\n",
    "$\\Delta w_j$ 被用于更新权重 $w_j$, 其计算公式为：\n",
    "\n",
    "$$\n",
    "\\Delta w_j = \\eta \\left(y^{(i)} - \\hat{y}^{(i)}\\right)x_j^{(i)}\n",
    "$$\n",
    "\n",
    "值得注意的是权重向量中的所有权重是同时更新的，也就是在 $\\Delta w_j$ 的所有权重被计算出来之前，我们并不会重复计算 $\\hat{y}^{(i)}$。更具体的，对于一个二维的数据集，我们将会进行如下更新：\n",
    "\n",
    "$$\n",
    "\\Delta w_0 = \\eta\\left(y^{(i)} - output^{(i)}\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Delta w_1 = \\eta\\left(y^{(i)} - output^{(i)}\\right)x_1^{(i)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Delta w_2 = \\eta\\left(y^{(i)} - output^{(i)}\\right)x_2^{(i)}\n",
    "$$\n",
    "\n",
    "来看一下这个简单的学习规则是如何精妙：\n",
    "\n",
    "感知器预测正确的类标签有两个场景，在这两个场景下权重保持不变：\n",
    "\n",
    "$$\n",
    "\\Delta w_j = \\eta\\left(-1^{(i)} - -1^{(i)}\\right)x_j^{(i)} = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Delta w_j = \\eta\\left(1^{(i)} - 1^{(i)}\\right)x_j^{(i)} = 0\n",
    "$$\n",
    "\n",
    "为了更好地直观理解乘法因子 $x_j^{(i)}$, 让我们来看另一个简单的例子：\n",
    "\n",
    "$$\n",
    "y^{(i)} = +1, ~\\hat{y}_j^{(i)} = -1, ~\\eta=1\n",
    "$$\n",
    "\n",
    "假设 $x_j^{(i)} = 0.5$, 真实类别为 +1，而我们错误地将这个样本分类为 -1. 在这种情况下，我们将会给相对应的权重增加 1，那么下次当我们再次遇到这个样本时，我们便会更有可能会得到一个高于阈值的 $z$ （权重增加，$z$ 自然也会增加）， 从而更有可能将该样本分类为 +1，即更有可能分类正确.\n",
    "\n",
    "$$\n",
    "\\Delta w_j^{(i)} = \\left(1^{(i)} - -1^{(i)}\\right)0.5^{(i)} = (2)0.5^{(i)} = 1\n",
    "$$\n",
    "\n",
    "权重的更新是与 $x_j$ 值的大小成比例的。举个例子，如果我们有另外一个样本 $x_j^{(i)} = 2$，它被错误地分类为 -1，\n",
    "\n",
    "$$\n",
    "\\Delta w_j = \\left(1^{(i)} - -1^{(i)}\\right)x^{(i)} = (2)2^{(i)} = 4\n",
    "$$\n",
    "\n",
    "这也就说，如果一个信号如果 “量比较大”，那么一旦分类错误，这个信号承担的责任也就越大，就越应该给它以越大幅度的修正。\n",
    "\n",
    "需要注意一点的是只有当两个类别是线性可分时，感知器算法才能保证收敛。如果两个类别不是线性可分，那么我们可以在训练集上设置一个最大的迭代次数(*epochs*), 或是设置一个可接受的错误分类的阈值。\n",
    "\n",
    "下面是感知器算法的 Python 实现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class Perceptron(object):\n",
    "    \"\"\"Perceptron classifier.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    eta: float\n",
    "        Learning rate (between 0.0 and 1.0)\n",
    "    n_iter: int\n",
    "        Passes over the training dataset.\n",
    "    Attributes\n",
    "    ----------\n",
    "    w_: 1d-array\n",
    "        Weights after fitting.\n",
    "    errors_: list\n",
    "        Number of misclassifications in every epoch.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, eta=0.01, n_iter=10):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit training data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: {array-like}, shape = [n_samples, n_features]\n",
    "            Training vectors, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "        y: array-like, shape = [n_samples]\n",
    "            Target values\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self: object\n",
    "        \"\"\"\n",
    "        self.w_ = np.zeros(1 + X.shape[1])\n",
    "        self.errors_ = []\n",
    "\n",
    "        for _ in range(self.n_iter):\n",
    "            errors = 0\n",
    "            for xi, target in zip(X, y):\n",
    "                update = self.eta * (target - self.predict(xi))\n",
    "                self.w_[1:] += update * xi\n",
    "                self.w_[0] += update\n",
    "                errors += int(update != 0.0)\n",
    "            self.errors_.append(errors)\n",
    "        return self\n",
    "\n",
    "    def net_input(self, X):\n",
    "        \"\"\"Calculate net input\"\"\"\n",
    "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Return class label after unit step\"\"\"\n",
    "        return np.where(self.net_input(X) >= 0.0, 1, -1)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "toc": {
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
